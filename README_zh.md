# ç»Ÿè®¡å­¦ä¹ æ¨¡å‹å¤ç°é¡¹ç›®

ä»é›¶å¼€å§‹å®ç°ç»å…¸ç»Ÿè®¡å­¦ä¹ ç®—æ³•ï¼Œé…åˆçœŸå®æ•°æ®é›†å’Œäº¤äº’å¼å¯è§†åŒ–ã€‚

**[English Version](./README.md)**

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å¤ç°ç»Ÿè®¡å­¦ä¹ ç†è®ºä¸­çš„æ ¸å¿ƒç®—æ³•ï¼ŒåŒ…æ‹¬å†³ç­–æ ‘å’Œæ¢¯åº¦æå‡æ¨¡å‹ã€‚æ¯ä¸ªå®ç°éƒ½åŒ…å«ï¼š

- **å®Œæ•´ç®—æ³•å®ç°**ï¼šä»é›¶å¼€å§‹å®ç°ï¼Œä¸ä¾èµ– scikit-learn
- **çœŸå®æ•°æ®éªŒè¯**ï¼šä½¿ç”¨é“¶è¡Œè´·æ¬¾æ•°æ®é›†è¿›è¡Œæµ‹è¯•
- **äº¤äº’å¼å¯è§†åŒ–**ï¼šåŸºäº Matplotlib çš„æ ‘ç»“æ„å¯è§†åŒ–
- **è¯¦ç»†æ–‡æ¡£æ³¨é‡Š**ï¼šåŒ…å«æ•°å­¦åŸç†å’Œä»£ç è§£é‡Š

## é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ DecisionTree.ipynb        # å†³ç­–æ ‘ï¼ˆID3ç®—æ³•ï¼‰
â”œâ”€â”€ XGBoost.ipynb             # XGBoost å®ç°
â”œâ”€â”€ data/
â”‚   â””â”€â”€ bankloan.csv          # é“¶è¡Œè´·æ¬¾æ•°æ®é›†ï¼ˆ5000æ ·æœ¬ï¼Œ14ç‰¹å¾ï¼‰
â””â”€â”€ README_zh.md              # æœ¬æ–‡ä»¶
```

## å®ç°çš„æ¨¡å‹

### 1. å†³ç­–æ ‘ (ID3ç®—æ³•)
**ä½ç½®**: `DecisionTree.ipynb`

#### æ ¸å¿ƒæ¦‚å¿µ
ID3ï¼ˆè¿­ä»£äºŒåˆ†å™¨ç¬¬3ä»£ï¼‰ç®—æ³•é€šè¿‡é€’å½’é€‰æ‹©**ä¿¡æ¯å¢ç›Š**æœ€å¤§çš„ç‰¹å¾æ¥åˆ†å‰²æ•°æ®é›†ï¼Œæ„å»ºå†³ç­–æ ‘ã€‚

#### å…³é”®ç»„ä»¶

**ä¿¡æ¯ç†µ**ï¼ˆShannonç†µï¼‰ï¼š
$$H(D) = -\sum_{k} p_k \log_2 p_k$$

å…¶ä¸­ $p_k$ æ˜¯æ•°æ®é›† $D$ ä¸­ç¬¬ $k$ ç±»çš„æ¯”ä¾‹ã€‚

**ä¿¡æ¯å¢ç›Š**ï¼š
$$IG(D, A) = H(D) - \sum_{v} \frac{|D_v|}{|D|} H(D_v)$$

å…¶ä¸­ $A$ æ˜¯ç‰¹å¾ï¼Œ$D_v$ æ˜¯ç‰¹å¾ $A$ ç­‰äºå€¼ $v$ çš„æ•°æ®å­é›†ã€‚

**ç®—æ³•æ­¥éª¤**ï¼š
1. è®¡ç®—å½“å‰æ•°æ®é›†çš„ç†µ
2. å¯¹æ¯ä¸ªç‰¹å¾è®¡ç®—ä¿¡æ¯å¢ç›Š
3. é€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ä½œä¸ºåˆ†å‰²ç‚¹
4. é€’å½’åˆ’åˆ†æ•°æ®é›†ï¼Œæ„å»ºå­æ ‘
5. åœæ­¢æ¡ä»¶ï¼š(a) èŠ‚ç‚¹ä¸­æ‰€æœ‰æ ·æœ¬å±äºåŒä¸€ç±»åˆ«ï¼Œæˆ– (b) æ‰€æœ‰ç‰¹å¾éƒ½å·²ä½¿ç”¨

#### å®ç°ç»†èŠ‚

**æ ‘çš„æ•°æ®ç»“æ„**ï¼šå­—å…¸é€’å½’è¡¨ç¤ºæ³•
```python
# ç¤ºä¾‹æ ‘ç»“æ„
{
    'Age': {
        0: {'Work': {0: 'No', 1: 'Yes'}},  # é’å¹´ -> æ˜¯å¦å·¥ä½œçš„åˆ†æ”¯
        1: 'Yes',                           # ä¸­å¹´ -> æ˜¯
        2: 'Yes'                            # è€å¹´ -> æ˜¯
    }
}
```

**æ ¸å¿ƒå‡½æ•°**ï¼š
- `calcShannonEnt(dataSet)`: è®¡ç®—æ•°æ®é›†ç†µ
- `chooseBestFeatureToSplit(dataSet)`: ä½¿ç”¨ä¿¡æ¯å¢ç›Šæ‰¾æœ€ä¼˜ç‰¹å¾
- `creatTree(dataset, labels)`: é€’å½’æ„å»ºå†³ç­–æ ‘
- `createPlot(myTree)`: Matplotlib å¯è§†åŒ–

**æ•°æ®é›†**ï¼šé“¶è¡Œè´·æ¬¾æ•°æ®é›†ï¼ˆç§»é™¤IDå4387ä¸ªæ ·æœ¬ï¼‰
- ç‰¹å¾ï¼šå¹´é¾„ã€å·¥ä½œã€æˆ¿äº§ã€è´·æ¬¾é¢åº¦ã€æ•™è‚²ç¨‹åº¦ç­‰ï¼ˆ13ä¸ªç‰¹å¾ï¼‰
- ç›®æ ‡ï¼šè´·æ¬¾æ‰¹å‡†ä¸å¦ï¼ˆæ˜¯/å¦ï¼‰

#### å¯è§†åŒ–æ•ˆæœ
åŸºäº Matplotlib çš„æ ‘å½¢å¯è§†åŒ–ï¼š
- è“è‰²èŠ‚ç‚¹ï¼šå†³ç­–èŠ‚ç‚¹ï¼ˆç‰¹å¾åˆ†å‰²ç‚¹ï¼‰
- é»„è‰²èŠ‚ç‚¹ï¼šå¶å­èŠ‚ç‚¹ï¼ˆé¢„æµ‹ç»“æœï¼‰
- è¾¹ä¸Šæ ‡ç­¾ï¼šç‰¹å¾å€¼å’Œå†³ç­–è·¯å¾„

---

### 2. XGBoost å®ç°
**ä½ç½®**: `XGBoost.ipynb`

*(è¯¦ç»†ä»‹ç»å¾…è¡¥å…… - å…ˆè¿›çš„æ¢¯åº¦æå‡æ–¹æ³•)*

---

## æ•°æ®æ ¼å¼

### CSV è½¬æ•°æ®é›†
`csv_to_dataset()` å‡½æ•°å°† CSV æ–‡ä»¶è½¬æ¢ä¸ºæ‰€éœ€æ ¼å¼ï¼š

```python
# è¿”å› (dataSet, labels)
# dataSet: [[ç‰¹å¾1, ç‰¹å¾2, ..., ç›®æ ‡], ...]
# labels: ['ç‰¹å¾1', 'ç‰¹å¾2', ..., 'ç‰¹å¾å']

dataSet, labels = csv_to_dataset(
    'data/bankloan.csv',
    exclude_cols=['ID']  # ç§»é™¤IDåˆ—
)
```

---

## æ•°å­¦åŸç†

### å†³ç­–æ ‘ç†è®º

**åœæ­¢æ¡ä»¶**ï¼š
1. **çº¯èŠ‚ç‚¹**ï¼šæ‰€æœ‰æ ·æœ¬å±äºåŒä¸€ç±»åˆ«
2. **ç‰¹å¾ç”¨å°½**ï¼šæ‰€æœ‰ç‰¹å¾éƒ½å·²ç”¨äºåˆ†å‰²
3. **å¤šæ•°è¡¨å†³**ï¼šç‰¹å¾ç”¨å®Œä½†æ ·æœ¬ä»æ··åˆæ—¶ï¼Œé€‰æ‹©å¤šæ•°ç±»

**å¤æ‚åº¦åˆ†æ**ï¼š
- æ—¶é—´ï¼š$O(n \cdot m \cdot \log m)$ï¼Œå…¶ä¸­ $n$ = æ ·æœ¬æ•°ï¼Œ$m$ = ç‰¹å¾æ•°
- ç©ºé—´ï¼š$O(m \cdot d)$ï¼Œå…¶ä¸­ $d$ = æ ‘æ·±åº¦

### ä¿¡æ¯è®ºåŸºç¡€

**ç†µ**è¡¡é‡é›†åˆä¸­çš„æ··ä¹±ç¨‹åº¦ï¼š
- $H = 0$ï¼šæ‰€æœ‰æ ·æœ¬åŒä¸€ç±»ï¼ˆçº¯ï¼‰
- $H = 1$ï¼šå‡åŒ€åˆ†å¸ƒï¼ˆæœ€å¤§æ··ä¹±ï¼‰

**ä¿¡æ¯å¢ç›Š**é‡åŒ–ç‰¹å¾å‡å°‘ä¸ç¡®å®šæ€§çš„ç¨‹åº¦ã€‚

---

## ä½¿ç”¨æ–¹æ³•

### è¿è¡Œå†³ç­–æ ‘

```python
# åŠ è½½æ•°æ®
dataSet_clean, labels_clean = csv_to_dataset(
    '/path/to/bankloan.csv',
    exclude_cols=['ID']
)

# æ„å»ºæ ‘
tree_clean = creatTree(dataSet_clean, labels_clean[:])

# å¯è§†åŒ–
createPlot(tree_clean)

# è·å–ç»Ÿè®¡ä¿¡æ¯
print(f"å¶å­èŠ‚ç‚¹æ•°: {getNumLeafs(tree_clean)}")
print(f"æ ‘çš„æ·±åº¦: {getTreeDepth(tree_clean)}")
```

### åœ¨é“¶è¡Œè´·æ¬¾æ•°æ®é›†ä¸Šçš„ç»“æœ

```
ğŸ¯ å†³ç­–æ ‘å¯è§†åŒ–ï¼ˆMatplotlibï¼‰
================================================================================
ğŸ“Š Matplotlibæ–¹æ¡ˆç»Ÿè®¡: å¶å­èŠ‚ç‚¹=4387, æ·±åº¦=3
```

åœ¨æ¸…ç†åçš„æ•°æ®é›†ä¸Šï¼Œæ ‘çš„æ·±åº¦ä¸º 3ï¼Œå…±æœ‰ 4,387 ä¸ªå¶å­èŠ‚ç‚¹ã€‚

---

## ä¾èµ–ç¯å¢ƒ

```
pandas>=1.0.0
matplotlib>=3.0.0
numpy>=1.18.0
```

### Jupyter ç¯å¢ƒè¦æ±‚
- Jupyter Notebook æˆ– JupyterLab
- Python 3.7+

---

## å®‰è£…ä¸è¿è¡Œ

### 1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/austinchennn/Statistical-Learning-reproduction.git
cd Statistical-Learning-reproduction
```

### 2. å®‰è£…ä¾èµ–
```bash
pip install pandas matplotlib numpy jupyter
```

### 3. è¿è¡Œ Notebook
```bash
jupyter notebook DecisionTree.ipynb
```

---

## ç®—æ³•å¯¹æ¯”ä¸æ‰©å±•

### å½“å‰å®ç°ï¼šID3ç®—æ³•
- **ä¼˜ç‚¹**ï¼šç®€å•æ˜“æ‡‚ã€ç»“æœå¯è§£é‡Šã€å¤„ç†åˆ†ç±»ç‰¹å¾
- **ç¼ºç‚¹**ï¼šå®¹æ˜“è¿‡æ‹Ÿåˆã€è´ªå¿ƒæ–¹æ³•ã€ä¸å¤„ç†ç¼ºå¤±å€¼

### æ½œåœ¨æ”¹è¿›æ–¹å‘
1. **å‰ªæ**ï¼šé€šè¿‡åå‰ªææˆ–å‡é”™å‰ªæå‡å°‘è¿‡æ‹Ÿåˆ
2. **C4.5ç®—æ³•**ï¼šä½¿ç”¨å¢ç›Šç‡å¤„ç†è¿ç»­ç‰¹å¾
3. **CARTç®—æ³•**ï¼šäºŒå‰æ ‘å½¢å¼ï¼Œæ”¯æŒå›å½’é—®é¢˜
4. **é›†æˆæ–¹æ³•**ï¼šä¸ Baggingï¼ˆéšæœºæ£®æ—ï¼‰æˆ– Boostingï¼ˆXGBoostï¼‰ç»“åˆ

---

## æ•°æ®é›†è¯´æ˜

### é“¶è¡Œè´·æ¬¾æ•°æ®é›† (`data/bankloan.csv`)
- **æ ·æœ¬æ•°**ï¼š5,000 æ¡ï¼ˆç§»é™¤IDå 4,387 æ¡ï¼‰
- **ç‰¹å¾æ•°**ï¼š13 ä¸ªç‰¹å¾ï¼ˆ1ä¸ªID + 12ä¸ªé¢„æµ‹ç‰¹å¾ï¼‰
- **ç›®æ ‡å˜é‡**ï¼šè´·æ¬¾æ‰¹å‡†çŠ¶æ€ï¼ˆæ˜¯/å¦ï¼‰
- **ç‰¹å¾ç±»å‹**ï¼šåŒ…å«åˆ†ç±»å’Œæ•°å€¼ç‰¹å¾
- **ç±»åˆ«åˆ†å¸ƒ**ï¼šå‡è¡¡çš„äºŒåˆ†ç±»

---

## å…³é”®ä»£ç è§£æ

### 1. ä¿¡æ¯ç†µè®¡ç®—

```python
def calcShannonEnt(dataSet) -> float:
    """
    è®¡ç®—æ•°æ®é›†çš„ä¿¡æ¯ç†µ
    dataSet: æ•°æ®é›†
    return: ä¿¡æ¯ç†µ
    """
    numexamples = len(dataSet)
    labelCounts = {}
    for featVec in dataSet:
        currentLabel = featVec[-1]
        if currentLabel not in labelCounts:
            labelCounts[currentLabel] = 0
        labelCounts[currentLabel] += 1

    shannonEnt = 0.0
    for key in labelCounts:
        prob = float(labelCounts[key]) / numexamples
        shannonEnt -= prob * log(prob, 2)  # å…¬å¼: -âˆ‘ p_k * log2(p_k)
    return shannonEnt
```

### 2. é€‰æ‹©æœ€ä¼˜ç‰¹å¾

```python
def chooseBestFeatureToSplit(dataSet) -> int:
    """
    ä½¿ç”¨ä¿¡æ¯å¢ç›Šé€‰æ‹©æœ€ä¼˜ç‰¹å¾
    """
    numFeatures = len(dataSet[0]) - 1
    baseEntropy = calcShannonEnt(dataSet)
    
    bestInfoGain = 0.0
    bestFeature_index = -1
    
    for i in range(numFeatures):
        featList_value = [example[i] for example in dataSet]
        uniqueVals = set(featList_value)
        newEntropy = 0.0
        
        for value in uniqueVals:
            subDataSet = splitDataSet(dataSet, i, value)
            prob = len(subDataSet) / float(len(dataSet))
            newEntropy += prob * calcShannonEnt(subDataSet)
        
        infoGain = baseEntropy - newEntropy  # ä¿¡æ¯å¢ç›Š
        
        if infoGain > bestInfoGain:
            bestInfoGain = infoGain
            bestFeature_index = i
    
    return bestFeature_index
```

### 3. é€’å½’æ„å»ºå†³ç­–æ ‘

```python
def creatTree(dataset, labels, featureLabels=[]):
    """
    é€’å½’æ„å»ºå†³ç­–æ ‘
    """
    classList = [example[-1] for example in dataset]
    
    # åœæ­¢æ¡ä»¶1ï¼šæ‰€æœ‰æ ·æœ¬åŒä¸€ç±»
    if classList.count(classList[0]) == len(classList):
        return classList[0]
    
    # åœæ­¢æ¡ä»¶2ï¼šæ‰€æœ‰ç‰¹å¾å·²ç”¨
    if len(dataset[0]) == 1:
        return majorityCnt(classList)
    
    # é€‰æ‹©æœ€ä¼˜ç‰¹å¾
    bestFeat_index = chooseBestFeatureToSplit(dataset)
    bestFeatLabel = labels[bestFeat_index]
    
    myTree = {bestFeatLabel: {}}
    del labels[bestFeat_index]
    
    # é€’å½’æ„å»ºå­æ ‘
    featValues = [example[bestFeat_index] for example in dataset]
    uniqueVals = set(featValues)
    
    for value in uniqueVals:
        sublabels = labels[:]
        myTree[bestFeatLabel][value] = creatTree(
            splitDataSet(dataset, bestFeat_index, value),
            sublabels,
            featureLabels
        )
    
    return myTree
```

---

## å‚è€ƒæ–‡çŒ®

1. Quinlan, J. R. (1986). "å½’çº³å†³ç­–æ ‘". Machine Learning, 1(1), 81-106.
2. Shannon, C. E. (1948). "é€šä¿¡çš„æ•°å­¦ç†è®º". Bell System Technical Journal.
3. Mitchell, T. M. (1997). "æœºå™¨å­¦ä¹ ". McGraw-Hill.
4. Hastie, T., Tibshirani, R., & Friedman, J. (2009). "ç»Ÿè®¡å­¦ä¹ çš„è¦ç´ ".

---

## é¡¹ç›®ç›®æ ‡

âœ… **æ•™è‚²ç›®çš„**ï¼šä»ç¬¬ä¸€åŸç†ç†è§£å†³ç­–æ ‘ç®—æ³•  
âœ… **ä»£ç å®ç°**ï¼šä»é›¶å¼€å§‹ç¼–å†™ç®—æ³•  
âœ… **å¯è§†åŒ–**ï¼šåˆ›å»ºå¯è§£é‡Šçš„è§†è§‰è¡¨ç°  
âœ… **å®è·µéªŒè¯**ï¼šåœ¨çœŸå®æ•°æ®é›†ä¸ŠéªŒè¯  
ğŸ”„ **æ‰©å±•å‘å±•**ï¼šæ·»åŠ é«˜çº§å˜ä½“ï¼ˆéšæœºæ£®æ—ã€æ¢¯åº¦æå‡ï¼‰

---

## ä½œè€…

Austin Chen

## è®¸å¯è¯

MIT è®¸å¯è¯ - è¯¦è§ LICENSE æ–‡ä»¶

---

## è´¡çŒ®æŒ‡å—

æ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®ï¼æ‚¨å¯ä»¥ï¼š
- æŠ¥å‘Šé—®é¢˜ï¼ˆIssueï¼‰
- æå‡ºæ”¹è¿›å»ºè®®
- æäº¤æ‹‰å–è¯·æ±‚ï¼ˆPull Requestï¼‰
- åˆ†äº«æ›´å¤šæ•°æ®é›†

---

**æœ€åæ›´æ–°æ—¶é—´**ï¼š2026å¹´1æœˆ4æ—¥
